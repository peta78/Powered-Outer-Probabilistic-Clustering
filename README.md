# Powered Outer Probabilistic Clustering

Clustering is one of the most important concepts for unsupervised learning in machine learning. While there are numerous clustering algorithms already, many, including the popular oneâ€”k-means algorithm, require the number of clusters to be specified in advance, a huge drawback. Some studies use the silhouette coefficient to determine the optimal number of clusters. In this study, we introduce a novel algorithm called Powered Outer Probabilistic Clustering, show how it works through back-propagation (starting with many clusters and ending with an optimal number of clusters) , and show that the algorithm converges to the expected (optimal) number of clusters on theoretical examples.

References:
* P. Taraba: [Powered Outer Probabilistic Clustering](http://www.iaeng.org/publication/WCECS2017/WCECS2017_pp394-398.pdf), Proceedings of the World Congress on Engineering and Computer Science, IAENG, October 2017 [[best paper award](http://www.iaeng.org/WCECS2017/awards.html)]
* P. Taraba: [Clustering for binary featured datasets](https://link.springer.com/chapter/10.1007/978-981-13-2191-7_10), [Transactions on Engineering Technologies: WCECS 2017](https://www.springer.com/us/book/9789811321900), Springer, 2019
* D.J. Brunner, P. Taraba, A. Ankolekar: [Personal data fusion](https://patents.google.com/patent/US11017343B2/en), US11017343B2, 2018, 2021

![ex1kmeans](./pics/ex1kmeans.png)
![ex1popc](./pics/ex1popc.png)
![ex2kmeans](./pics/ex2kmeans.png)
![ex2popc](./pics/ex2popc.png)
![ex3kmeans](./pics/ex3kmeans.png)
![ex3popc](./pics/ex3popc.png)

